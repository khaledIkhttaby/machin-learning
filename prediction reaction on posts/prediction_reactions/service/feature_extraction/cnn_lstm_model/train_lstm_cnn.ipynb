{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from prediction_reactions.service.preprocessing_data.prepearing_data import resources\n",
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   haha  sad  love  angry  wow  \\\n0    10   12  1092      2   49   \n1   195    1   315      0    5   \n2     0    0   151      0   12   \n3     0    1     5      3    4   \n4     1   19   159      0    0   \n\n                                             content  \\\n0  امطار  خفيفة تهطل على العاصمة دمشق  عدسة: Nour...   \n1  . قاعدين بلا شغل وعم نقبض رواتب 🙂.. شو بدنا أح...   \n2  رادار البروق الآن | زخات مطر مصحوبة بالبروق بد...   \n3  🔊    نشرة أسعار الدولار   💯https://spprices.co...   \n4  الشارع يتألم .. لكنه تائه في تحديد الخيارات .....   \n\n                                        page_name  sumreactions  \\\n0                       يوميات قذيفة هاون في دمشق          1165   \n1                           Lattakia Fire Brigade           516   \n2                  Hawa Al Sham Weather هوى الشام           163   \n3          الأسعار بالليرة السورية - SPPrices.com            13   \n4  رفيق نصرالله - المركز الدولي للاعلام والدراسات           179   \n\n                                        contentclean  len_text  \n0                 امطار خفيفه تهطل العاصمه دمشق عدسه      34.0  \n1  قاعدين بلا شغل نقبض رواتب 🙂 احلى 🙃 اللاذقيه لل...      93.0  \n2  رادار البروق زخات مطر مصحوبه بالبروق بدات قليل...     742.0  \n3                               نشره اسعار الدولار 💯      20.0  \n4  الشارع يتالم لكنه تائه تحديد الخيارات عندما يت...     193.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>haha</th>\n      <th>sad</th>\n      <th>love</th>\n      <th>angry</th>\n      <th>wow</th>\n      <th>content</th>\n      <th>page_name</th>\n      <th>sumreactions</th>\n      <th>contentclean</th>\n      <th>len_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>12</td>\n      <td>1092</td>\n      <td>2</td>\n      <td>49</td>\n      <td>امطار  خفيفة تهطل على العاصمة دمشق  عدسة: Nour...</td>\n      <td>يوميات قذيفة هاون في دمشق</td>\n      <td>1165</td>\n      <td>امطار خفيفه تهطل العاصمه دمشق عدسه</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>195</td>\n      <td>1</td>\n      <td>315</td>\n      <td>0</td>\n      <td>5</td>\n      <td>. قاعدين بلا شغل وعم نقبض رواتب 🙂.. شو بدنا أح...</td>\n      <td>Lattakia Fire Brigade</td>\n      <td>516</td>\n      <td>قاعدين بلا شغل نقبض رواتب 🙂 احلى 🙃 اللاذقيه لل...</td>\n      <td>93.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>151</td>\n      <td>0</td>\n      <td>12</td>\n      <td>رادار البروق الآن | زخات مطر مصحوبة بالبروق بد...</td>\n      <td>Hawa Al Sham Weather هوى الشام</td>\n      <td>163</td>\n      <td>رادار البروق زخات مطر مصحوبه بالبروق بدات قليل...</td>\n      <td>742.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>🔊    نشرة أسعار الدولار   💯https://spprices.co...</td>\n      <td>الأسعار بالليرة السورية - SPPrices.com</td>\n      <td>13</td>\n      <td>نشره اسعار الدولار 💯</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>19</td>\n      <td>159</td>\n      <td>0</td>\n      <td>0</td>\n      <td>الشارع يتألم .. لكنه تائه في تحديد الخيارات .....</td>\n      <td>رفيق نصرالله - المركز الدولي للاعلام والدراسات</td>\n      <td>179</td>\n      <td>الشارع يتالم لكنه تائه تحديد الخيارات عندما يت...</td>\n      <td>193.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "data=pd.read_csv(resources+\"data/Data_cleaning_with_content.csv\")\n",
    "data=data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data['percent_haha']=data['haha']/data['sumreactions']\n",
    "data['percent_sad']=data['sad']/data['sumreactions']\n",
    "data['percent_love']=data['love']/data['sumreactions']\n",
    "data['percent_angry']=data['angry']/data['sumreactions']\n",
    "data['percent_wow']=data['wow']/data['sumreactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "my_data=data[['contentclean','percent_haha','percent_sad','percent_love','percent_angry','percent_wow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Y_train=my_data[['percent_haha','percent_sad','percent_love','percent_angry','percent_wow']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "maxlen=100\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "\n",
    "tokenizer.fit_on_texts(my_data['contentclean'].values)\n",
    "\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(my_data['contentclean'].values)\n",
    "    # X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "        # Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "        # Pad sequences with zeros\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def creat_model_cnn(vocab_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, 50, input_length=100))\n",
    "    model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(13,activation=\"softmax\"))\n",
    "    model.add(layers.Dense(5))\n",
    "    model.compile(optimizer='adam',\n",
    "                        loss='mse',\n",
    "                    )\n",
    "    return model\n",
    "def creat_model_lstm(vocab_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, 50, input_length=100))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(256)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(13,activation=\"softmax\"))\n",
    "    model.add(layers.Dense(5))\n",
    "    model.compile(optimizer='adam',\n",
    "                        loss='mse',\n",
    "                         )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_regression=creat_model_cnn(vocab_size)\n",
    "model_cnn_regression.fit(X_train,Y_train,batch_size=128,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_regression=creat_model_lstm(vocab_size)\n",
    "model_lstm_regression.fit(X_train,Y_train,batch_size=128,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_regression.save(resources+\"models/\"+\"model_cnn_regression.h5\")\n",
    "model_lstm_regression.save(resources+\"models/\"+\"model_lstm_regression.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(resources+\"models/\"+\"tokenizer_model_cnn_lstm_regression.pickle\",\"wb\") as file:\n",
    "    pickle.dump(tokenizer,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}